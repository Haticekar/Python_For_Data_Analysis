{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ã–RNEK\n",
    "import pandas as pd \n",
    "data = {\n",
    "    \"Name\" : [\"Ali\", \"AyÅŸe\", \"Mehmet\", None],\n",
    "    \"Age\" : [25,30,None,22],\n",
    "    \"Gender\" : [\"Male\", \"Female\", \"Mle\", \"Female\"]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df[\"Gender\"] = df[\"Gender\"].replace(\"Mle\", \"Male\") #hatalÄ± veri \n",
    "df[\"Age\"]= df[\"Age\"].fillna(df[\"Age\"].mean()) # eksik yaÅŸ \n",
    "df = df.dropna(subset=[\"Name\"]) #ismi eksik olanÄ± sil \n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haticekar/Desktop/anaconda/anaconda3/envs/python_course/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "#loading data\n",
    "dataset = load_dataset(\"lukebarousse/data_jobs\")\n",
    "df = dataset[\"train\"].to_pandas()\n",
    "\n",
    "#data clenup\n",
    "df[\"job_posted_date\"] = pd.to_datetime(df[\"job_posted_date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“Œ Pandas ile En SÄ±k YapÄ±lan Data Cleaning Ä°ÅŸlemleri\n",
    "\n",
    "| Ä°ÅŸlem                        | AÃ§Ä±klama                                           | Pandas Ã–rnek Kodu                                  |\n",
    "|-----------------------------|----------------------------------------------------|----------------------------------------------------|\n",
    "| Eksik verileri bulma        | NaN veya boÅŸ deÄŸerleri tespit etme                 | `df.isnull().sum()`                                |\n",
    "| Eksik verileri temizleme    | Eksik verileri silme veya doldurma                 | `df.dropna()` / `df.fillna(0)`                     |\n",
    "| Veri tipi dÃ¶nÃ¼ÅŸtÃ¼rme        | `str`, `int`, `datetime` gibi tip dÃ¶nÃ¼ÅŸÃ¼mleri      | `df['date'] = pd.to_datetime(df['date'])`          |\n",
    "| Ã‡ift kayÄ±tlarÄ± silme        | AynÄ± satÄ±rdan birden fazla varsa temizleme         | `df.drop_duplicates()`                             |\n",
    "| HatalÄ± verileri dÃ¼zeltme    | YanlÄ±ÅŸ girilmiÅŸ verileri doÄŸru olanla deÄŸiÅŸtirme   | `df['gender'].replace('Mle', 'Male')`              |\n",
    "| Gereksiz sÃ¼tun/satÄ±r silme  | Analize dahil edilmeyecek sÃ¼tun veya satÄ±rlarÄ± atma| `df.drop(['Unnamed: 0'], axis=1)`                  |\n",
    "| Metin verileri temizleme    | BoÅŸluklarÄ± silme, kÃ¼Ã§Ã¼k/bÃ¼yÃ¼k harf dÃ¼zeni          | `df['name'] = df['name'].str.strip().str.lower()`  |\n",
    "| AykÄ±rÄ± deÄŸerleri filtreleme | Ã‡ok uÃ§ta olan istatistiksel deÄŸerleri temizleme    | `df[df['salary'] < 300000]`                        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115000.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"salary_year_avg\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.97999954223633"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"salary_hour_avg\"].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Missing Data\n",
    "#### Notes\n",
    "- `df.dropna()`: Drop missing values.\n",
    "##### Examples\n",
    "Here we are only drop values if all of their values are missing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 785741 entries, 0 to 785740\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Non-Null Count   Dtype         \n",
      "---  ------                 --------------   -----         \n",
      " 0   job_title_short        785741 non-null  object        \n",
      " 1   job_title              785740 non-null  object        \n",
      " 2   job_location           784696 non-null  object        \n",
      " 3   job_via                785733 non-null  object        \n",
      " 4   job_schedule_type      773074 non-null  object        \n",
      " 5   job_work_from_home     785741 non-null  bool          \n",
      " 6   search_location        785741 non-null  object        \n",
      " 7   job_posted_date        785741 non-null  datetime64[ns]\n",
      " 8   job_no_degree_mention  785741 non-null  bool          \n",
      " 9   job_health_insurance   785741 non-null  bool          \n",
      " 10  job_country            785692 non-null  object        \n",
      " 11  salary_rate            33067 non-null   object        \n",
      " 12  salary_year_avg        22003 non-null   float64       \n",
      " 13  salary_hour_avg        10662 non-null   float64       \n",
      " 14  company_name           785723 non-null  object        \n",
      " 15  job_skills             668704 non-null  object        \n",
      " 16  job_type_skills        668704 non-null  object        \n",
      "dtypes: bool(3), datetime64[ns](1), float64(2), object(11)\n",
      "memory usage: 86.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_cleaned = df.dropna(how=\"all\")\n",
    "df_cleaned.info() #her sÃ¼tundaki eksik (non-null ) veri sayÄ±sÄ±nÄ± ve veri tiplerini \n",
    "#how='all': Sadece tÃ¼m sÃ¼tunlarÄ± NaN olan satÄ±rlarÄ± sil.\n",
    "#Alternatif olarak how='any' deseydin, herhangi bir hÃ¼cre NaN ise o satÄ±r silinirdi (daha agresif temizlik olurdu)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now all we can do is drop values if they're missing. But that's not useful right now because our DataFrame didn't have any. \n",
    "\n",
    "So, what if we wanted to fill the missing values with something else? This is expecially useful so we don't run into errors when dealing with NaN values.\n",
    "\n",
    "### Fillna\n",
    "\n",
    "#### Notes\n",
    "\n",
    "- `df.fillna()`: Fill missing values\n",
    "\n",
    "#### Examples\n",
    "\n",
    "Let's fill in instances where there's no salary info (aka these columns have NaN values `salary_rate`, `salary_year_avg`, `salary_hour_avg`) with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary_rate</th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_hour_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  salary_rate  salary_year_avg  salary_hour_avg\n",
       "0        None              NaN              NaN\n",
       "1        None              NaN              NaN\n",
       "2        None              NaN              NaN\n",
       "3        None              NaN              NaN\n",
       "4        None              NaN              NaN\n",
       "5        None              NaN              NaN\n",
       "6        None              NaN              NaN\n",
       "7        None              NaN              NaN\n",
       "8        None              NaN              NaN\n",
       "9        None              NaN              NaN"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.iloc[:10, 11:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 785741 entries, 0 to 785740\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Non-Null Count   Dtype         \n",
      "---  ------                 --------------   -----         \n",
      " 0   job_title_short        785741 non-null  object        \n",
      " 1   job_title              785741 non-null  object        \n",
      " 2   job_location           785741 non-null  object        \n",
      " 3   job_via                785741 non-null  object        \n",
      " 4   job_schedule_type      785741 non-null  object        \n",
      " 5   job_work_from_home     785741 non-null  bool          \n",
      " 6   search_location        785741 non-null  object        \n",
      " 7   job_posted_date        785741 non-null  datetime64[ns]\n",
      " 8   job_no_degree_mention  785741 non-null  bool          \n",
      " 9   job_health_insurance   785741 non-null  bool          \n",
      " 10  job_country            785741 non-null  object        \n",
      " 11  salary_rate            785741 non-null  object        \n",
      " 12  salary_year_avg        785741 non-null  float64       \n",
      " 13  salary_hour_avg        785741 non-null  float64       \n",
      " 14  company_name           785741 non-null  object        \n",
      " 15  job_skills             785741 non-null  object        \n",
      " 16  job_type_skills        785741 non-null  object        \n",
      "dtypes: bool(3), datetime64[ns](1), float64(2), object(11)\n",
      "memory usage: 86.2+ MB\n"
     ]
    }
   ],
   "source": [
    "fill_values = [\"salary_rate\", \"salary_year_avg\",\"salary_hour_avg\"] #sadece bir liste  df_cleaned -> boÅŸ satÄ±rlarÄ± sildiÄŸimi< veri seti \n",
    "df_filled = df_cleaned.fillna(0) # eksik olan deÄŸerleri 0 ile doldurur.\n",
    "df_filled.info() #KaÃ§ satÄ±dr ve sÃ¼tun var? -Hangi sÃ¼tunda kaÃ§ null olmayan deÄŸer (non-null) var?-Her sÃ¼tunun tipi (int, float, object vs.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary_rate</th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_hour_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  salary_rate  salary_year_avg  salary_hour_avg\n",
       "0           0              0.0              0.0\n",
       "1           0              0.0              0.0\n",
       "2           0              0.0              0.0\n",
       "3           0              0.0              0.0\n",
       "4           0              0.0              0.0\n",
       "5           0              0.0              0.0\n",
       "6           0              0.0              0.0\n",
       "7           0              0.0              0.0\n",
       "8           0              0.0              0.0\n",
       "9           0              0.0              0.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filled.iloc[:10, 11:14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Duplicates\n",
    "\n",
    "### Notes\n",
    "\n",
    "* `drop_duplicates()`: Remove duplicate rows.\n",
    "* Analysts will often need to clean up data and one of the most common issues we run into is duplicate values. \n",
    "\n",
    "### Examples\n",
    "\n",
    "Now that we've dealt with NaN values. Let's continue cleaning the data by removing any duplicate rows.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 785640 entries, 0 to 785740\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Non-Null Count   Dtype         \n",
      "---  ------                 --------------   -----         \n",
      " 0   job_title_short        785640 non-null  object        \n",
      " 1   job_title              785640 non-null  object        \n",
      " 2   job_location           785640 non-null  object        \n",
      " 3   job_via                785640 non-null  object        \n",
      " 4   job_schedule_type      785640 non-null  object        \n",
      " 5   job_work_from_home     785640 non-null  bool          \n",
      " 6   search_location        785640 non-null  object        \n",
      " 7   job_posted_date        785640 non-null  datetime64[ns]\n",
      " 8   job_no_degree_mention  785640 non-null  bool          \n",
      " 9   job_health_insurance   785640 non-null  bool          \n",
      " 10  job_country            785640 non-null  object        \n",
      " 11  salary_rate            785640 non-null  object        \n",
      " 12  salary_year_avg        785640 non-null  float64       \n",
      " 13  salary_hour_avg        785640 non-null  float64       \n",
      " 14  company_name           785640 non-null  object        \n",
      " 15  job_skills             785640 non-null  object        \n",
      " 16  job_type_skills        785640 non-null  object        \n",
      "dtypes: bool(3), datetime64[ns](1), float64(2), object(11)\n",
      "memory usage: 92.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_unique = df_filled.drop_duplicates()\n",
    "df_unique.info()\n",
    "\n",
    "#drop_duplicates() fonksiyonu, aynÄ± satÄ±rdan birden fazla varsa (yani birebir aynÄ± deÄŸerler tÃ¼m sÃ¼tunlarda varsa) bu tekrarlÄ± satÄ±rlarÄ± siler.\n",
    "#Sadece ilk gÃ¶rÃ¼len satÄ±rÄ± tutar, diÄŸerlerini siler.\n",
    "#Veri temizliÄŸinde Ã§ok kullanÄ±lÄ±r Ã§Ã¼nkÃ¼ bazÄ± veriler yanlÄ±ÅŸlÄ±kla birden fazla defa kaydedilmiÅŸ olabilir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you compare that with the original DataFrame which had 787686 entries. This new DataFrame `df_unique` has 787577 entries. It removed 109 entries. \n",
    "\n",
    "Now let's see what would happen if we tried to remove duplicates from `job_title`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 234674 entries, 0 to 785740\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Non-Null Count   Dtype         \n",
      "---  ------                 --------------   -----         \n",
      " 0   job_title_short        234674 non-null  object        \n",
      " 1   job_title              234674 non-null  object        \n",
      " 2   job_location           234674 non-null  object        \n",
      " 3   job_via                234674 non-null  object        \n",
      " 4   job_schedule_type      234674 non-null  object        \n",
      " 5   job_work_from_home     234674 non-null  bool          \n",
      " 6   search_location        234674 non-null  object        \n",
      " 7   job_posted_date        234674 non-null  datetime64[ns]\n",
      " 8   job_no_degree_mention  234674 non-null  bool          \n",
      " 9   job_health_insurance   234674 non-null  bool          \n",
      " 10  job_country            234674 non-null  object        \n",
      " 11  salary_rate            234674 non-null  object        \n",
      " 12  salary_year_avg        234674 non-null  float64       \n",
      " 13  salary_hour_avg        234674 non-null  float64       \n",
      " 14  company_name           234674 non-null  object        \n",
      " 15  job_skills             234674 non-null  object        \n",
      " 16  job_type_skills        234674 non-null  object        \n",
      "dtypes: bool(3), datetime64[ns](1), float64(2), object(11)\n",
      "memory usage: 27.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_unique = df_filled.drop_duplicates(subset=[\"job_title\"]) #burada job_title a bakÄ±yor daha sonra aynÄ± job_title a sahip olan bÃ¼tÃ¼n satÄ±rlarÄ± siliyor \n",
    "df_unique.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # drop_duplicates() â€“ TÃ¼m satÄ±rlar aynÄ± olanlarÄ± siler- subset[\"job_title\"\"]\n",
    "| job_title    | salary | location |\n",
    "|--------------|--------|----------|\n",
    "| Data Analyst | 100000 | US       |\n",
    "| Data Analyst | 100000 | US       |\n",
    "| Data Analyst | 120000 | US       |\n",
    "| Data Eng.    | 110000 | Canada   |\n",
    "\n",
    "# drop_duplicates() sonrasÄ±\n",
    "| job_title    | salary | location |\n",
    "|--------------|--------|----------|\n",
    "| Data Analyst | 100000 | US       |\n",
    "| Data Analyst | 120000 | US       |\n",
    "| Data Eng.    | 110000 | Canada   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title_short</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_via</th>\n",
       "      <th>job_schedule_type</th>\n",
       "      <th>job_work_from_home</th>\n",
       "      <th>search_location</th>\n",
       "      <th>job_posted_date</th>\n",
       "      <th>job_no_degree_mention</th>\n",
       "      <th>job_health_insurance</th>\n",
       "      <th>job_country</th>\n",
       "      <th>salary_rate</th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_hour_avg</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>job_type_skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Senior Clinical Data Engineer / Principal Clin...</td>\n",
       "      <td>Watertown, CT</td>\n",
       "      <td>via Work Nearby</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Texas, United States</td>\n",
       "      <td>2023-06-16 13:44:15</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Boehringer Ingelheim</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Guadalajara, Jalisco, Mexico</td>\n",
       "      <td>via BeBee MÃ©xico</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>2023-01-14 13:18:07</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Hewlett Packard Enterprise</td>\n",
       "      <td>['r', 'python', 'sql', 'nosql', 'power bi', 't...</td>\n",
       "      <td>{'analyst_tools': ['power bi', 'tableau'], 'pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer/Scientist/Analyst, Mid or Senior...</td>\n",
       "      <td>Berlin, Germany</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2023-10-10 13:14:55</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ALPHA Augmented Services</td>\n",
       "      <td>['python', 'sql', 'c#', 'azure', 'airflow', 'd...</td>\n",
       "      <td>{'analyst_tools': ['dax'], 'cloud': ['azure'],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>LEAD ENGINEER - PRINCIPAL ANALYST - PRINCIPAL ...</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>via Diversity.com</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Texas, United States</td>\n",
       "      <td>2023-07-04 13:01:41</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Southwest Research Institute</td>\n",
       "      <td>['python', 'c++', 'java', 'matlab', 'aws', 'te...</td>\n",
       "      <td>{'cloud': ['aws'], 'libraries': ['tensorflow',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer- Sr Jobs</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>via Clearance Jobs</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>2023-08-07 14:29:36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Kristina Daniel</td>\n",
       "      <td>['bash', 'python', 'oracle', 'aws', 'ansible',...</td>\n",
       "      <td>{'cloud': ['oracle', 'aws'], 'other': ['ansibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>GCP Data Engineer</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>via ZipRecruiter</td>\n",
       "      <td>Contractor and Temp work</td>\n",
       "      <td>True</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>2023-11-07 14:01:59</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>smart folks inc</td>\n",
       "      <td>['python', 'sql', 'gcp']</td>\n",
       "      <td>{'cloud': ['gcp'], 'programming': ['python', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Senior Data Engineer  - GCP Cloud</td>\n",
       "      <td>Dearborn, MI</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Florida, United States</td>\n",
       "      <td>2023-03-27 13:18:18</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Miracle Software Systems, Inc</td>\n",
       "      <td>['sql', 'python', 'java', 'sql server', 'gcp',...</td>\n",
       "      <td>{'cloud': ['gcp', 'bigquery'], 'databases': ['...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>True</td>\n",
       "      <td>Romania</td>\n",
       "      <td>2023-12-07 13:40:49</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Romania</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Zitec</td>\n",
       "      <td>['sql', 'nosql', 'gcp', 'azure', 'aws', 'bigqu...</td>\n",
       "      <td>{'cloud': ['gcp', 'azure', 'aws', 'bigquery', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Technology &amp; Operations Business Analyst</td>\n",
       "      <td>Copenhagen, Denmark</td>\n",
       "      <td>via Trabajo.org</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>2023-06-05 13:44:34</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Hempel</td>\n",
       "      <td>['excel', 'powerpoint', 'power bi']</td>\n",
       "      <td>{'analyst_tools': ['excel', 'powerpoint', 'pow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist II</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>via ZipRecruiter</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>True</td>\n",
       "      <td>New York, United States</td>\n",
       "      <td>2023-04-23 13:02:57</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Radwell International, LLC</td>\n",
       "      <td>['sql', 'python', 'r', 'mongodb', 'mongodb', '...</td>\n",
       "      <td>{'analyst_tools': ['excel'], 'cloud': ['azure'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        job_title_short                                          job_title  \\\n",
       "0  Senior Data Engineer  Senior Clinical Data Engineer / Principal Clin...   \n",
       "1          Data Analyst                                       Data Analyst   \n",
       "2         Data Engineer  Data Engineer/Scientist/Analyst, Mid or Senior...   \n",
       "3         Data Engineer  LEAD ENGINEER - PRINCIPAL ANALYST - PRINCIPAL ...   \n",
       "4         Data Engineer                             Data Engineer- Sr Jobs   \n",
       "5         Data Engineer                                  GCP Data Engineer   \n",
       "6  Senior Data Engineer                  Senior Data Engineer  - GCP Cloud   \n",
       "7         Data Engineer                                      Data Engineer   \n",
       "8      Business Analyst           Technology & Operations Business Analyst   \n",
       "9        Data Scientist                                  Data Scientist II   \n",
       "\n",
       "                   job_location             job_via         job_schedule_type  \\\n",
       "0                 Watertown, CT     via Work Nearby                 Full-time   \n",
       "1  Guadalajara, Jalisco, Mexico    via BeBee MÃ©xico                 Full-time   \n",
       "2               Berlin, Germany        via LinkedIn                 Full-time   \n",
       "3               San Antonio, TX   via Diversity.com                 Full-time   \n",
       "4                Washington, DC  via Clearance Jobs                 Full-time   \n",
       "5                      Anywhere    via ZipRecruiter  Contractor and Temp work   \n",
       "6                  Dearborn, MI        via LinkedIn                 Full-time   \n",
       "7                      Anywhere        via LinkedIn                 Full-time   \n",
       "8           Copenhagen, Denmark     via Trabajo.org                 Full-time   \n",
       "9                      Anywhere    via ZipRecruiter                 Full-time   \n",
       "\n",
       "   job_work_from_home          search_location     job_posted_date  \\\n",
       "0               False     Texas, United States 2023-06-16 13:44:15   \n",
       "1               False                   Mexico 2023-01-14 13:18:07   \n",
       "2               False                  Germany 2023-10-10 13:14:55   \n",
       "3               False     Texas, United States 2023-07-04 13:01:41   \n",
       "4               False                    Sudan 2023-08-07 14:29:36   \n",
       "5                True                  Georgia 2023-11-07 14:01:59   \n",
       "6               False   Florida, United States 2023-03-27 13:18:18   \n",
       "7                True                  Romania 2023-12-07 13:40:49   \n",
       "8               False                  Denmark 2023-06-05 13:44:34   \n",
       "9                True  New York, United States 2023-04-23 13:02:57   \n",
       "\n",
       "   job_no_degree_mention  job_health_insurance    job_country salary_rate  \\\n",
       "0                  False                 False  United States           0   \n",
       "1                  False                 False         Mexico           0   \n",
       "2                  False                 False        Germany           0   \n",
       "3                   True                 False  United States           0   \n",
       "4                  False                 False          Sudan           0   \n",
       "5                  False                 False  United States           0   \n",
       "6                  False                 False  United States           0   \n",
       "7                  False                 False        Romania           0   \n",
       "8                  False                 False        Denmark           0   \n",
       "9                  False                 False  United States           0   \n",
       "\n",
       "   salary_year_avg  salary_hour_avg                   company_name  \\\n",
       "0              0.0              0.0           Boehringer Ingelheim   \n",
       "1              0.0              0.0     Hewlett Packard Enterprise   \n",
       "2              0.0              0.0       ALPHA Augmented Services   \n",
       "3              0.0              0.0   Southwest Research Institute   \n",
       "4              0.0              0.0                Kristina Daniel   \n",
       "5              0.0              0.0                smart folks inc   \n",
       "6              0.0              0.0  Miracle Software Systems, Inc   \n",
       "7              0.0              0.0                          Zitec   \n",
       "8              0.0              0.0                         Hempel   \n",
       "9              0.0              0.0     Radwell International, LLC   \n",
       "\n",
       "                                          job_skills  \\\n",
       "0                                                  0   \n",
       "1  ['r', 'python', 'sql', 'nosql', 'power bi', 't...   \n",
       "2  ['python', 'sql', 'c#', 'azure', 'airflow', 'd...   \n",
       "3  ['python', 'c++', 'java', 'matlab', 'aws', 'te...   \n",
       "4  ['bash', 'python', 'oracle', 'aws', 'ansible',...   \n",
       "5                           ['python', 'sql', 'gcp']   \n",
       "6  ['sql', 'python', 'java', 'sql server', 'gcp',...   \n",
       "7  ['sql', 'nosql', 'gcp', 'azure', 'aws', 'bigqu...   \n",
       "8                ['excel', 'powerpoint', 'power bi']   \n",
       "9  ['sql', 'python', 'r', 'mongodb', 'mongodb', '...   \n",
       "\n",
       "                                     job_type_skills  \n",
       "0                                                  0  \n",
       "1  {'analyst_tools': ['power bi', 'tableau'], 'pr...  \n",
       "2  {'analyst_tools': ['dax'], 'cloud': ['azure'],...  \n",
       "3  {'cloud': ['aws'], 'libraries': ['tensorflow',...  \n",
       "4  {'cloud': ['oracle', 'aws'], 'other': ['ansibl...  \n",
       "5  {'cloud': ['gcp'], 'programming': ['python', '...  \n",
       "6  {'cloud': ['gcp', 'bigquery'], 'databases': ['...  \n",
       "7  {'cloud': ['gcp', 'azure', 'aws', 'bigquery', ...  \n",
       "8  {'analyst_tools': ['excel', 'powerpoint', 'pow...  \n",
       "9  {'analyst_tools': ['excel'], 'cloud': ['azure'...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of original df:  785741\n",
      "Length of drop duplicates:  234674\n",
      "Rows Dropped:  551067\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of original df: \", len(df_filled))\n",
    "print(\"Length of drop duplicates: \", len(df_unique))\n",
    "print(\"Rows Dropped: \", len(df_filled)-len(df_unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title_short</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_via</th>\n",
       "      <th>job_schedule_type</th>\n",
       "      <th>job_work_from_home</th>\n",
       "      <th>search_location</th>\n",
       "      <th>job_posted_date</th>\n",
       "      <th>job_no_degree_mention</th>\n",
       "      <th>job_health_insurance</th>\n",
       "      <th>job_country</th>\n",
       "      <th>salary_rate</th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_hour_avg</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>job_type_skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Senior Clinical Data Engineer / Principal Clin...</td>\n",
       "      <td>Watertown, CT</td>\n",
       "      <td>via Work Nearby</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Texas, United States</td>\n",
       "      <td>2023-06-16 13:44:15</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boehringer Ingelheim</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Guadalajara, Jalisco, Mexico</td>\n",
       "      <td>via BeBee MÃ©xico</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>2023-01-14 13:18:07</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hewlett Packard Enterprise</td>\n",
       "      <td>['r', 'python', 'sql', 'nosql', 'power bi', 't...</td>\n",
       "      <td>{'analyst_tools': ['power bi', 'tableau'], 'pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer/Scientist/Analyst, Mid or Senior...</td>\n",
       "      <td>Berlin, Germany</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2023-10-10 13:14:55</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALPHA Augmented Services</td>\n",
       "      <td>['python', 'sql', 'c#', 'azure', 'airflow', 'd...</td>\n",
       "      <td>{'analyst_tools': ['dax'], 'cloud': ['azure'],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>LEAD ENGINEER - PRINCIPAL ANALYST - PRINCIPAL ...</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>via Diversity.com</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Texas, United States</td>\n",
       "      <td>2023-07-04 13:01:41</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southwest Research Institute</td>\n",
       "      <td>['python', 'c++', 'java', 'matlab', 'aws', 'te...</td>\n",
       "      <td>{'cloud': ['aws'], 'libraries': ['tensorflow',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer- Sr Jobs</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>via Clearance Jobs</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>2023-08-07 14:29:36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kristina Daniel</td>\n",
       "      <td>['bash', 'python', 'oracle', 'aws', 'ansible',...</td>\n",
       "      <td>{'cloud': ['oracle', 'aws'], 'other': ['ansibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785736</th>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>DevOps Engineer</td>\n",
       "      <td>Singapura</td>\n",
       "      <td>melalui Trabajo.org</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>2023-03-13 06:16:16</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CAREERSTAR INTERNATIONAL PTE. LTD.</td>\n",
       "      <td>['bash', 'python', 'perl', 'linux', 'unix', 'k...</td>\n",
       "      <td>{'os': ['linux', 'unix'], 'other': ['kubernete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785737</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>CRM Data Analyst</td>\n",
       "      <td>Bad Rodach, Jerman</td>\n",
       "      <td>melalui BeBee Deutschland</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2023-03-12 06:18:18</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HABA FAMILYGROUP</td>\n",
       "      <td>['sas', 'sas', 'sql', 'excel']</td>\n",
       "      <td>{'analyst_tools': ['sas', 'excel'], 'programmi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785738</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Commercial Analyst - Start Now</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>melalui Ricebowl</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>2023-03-12 06:32:36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lendlease Corporation</td>\n",
       "      <td>['powerpoint', 'excel']</td>\n",
       "      <td>{'analyst_tools': ['powerpoint', 'excel']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785739</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Principal Associate, Data Engineer (Remote-Eli...</td>\n",
       "      <td>Newark, New Jersey, Amerika Serikat</td>\n",
       "      <td>melalui Recruit.net</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>2023-03-12 06:32:15</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Capital One</td>\n",
       "      <td>['python', 'go', 'nosql', 'sql', 'mongo', 'she...</td>\n",
       "      <td>{'cloud': ['aws', 'snowflake', 'azure', 'redsh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785740</th>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>AWS System Analyst</td>\n",
       "      <td>India</td>\n",
       "      <td>melalui Trigyn</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>India</td>\n",
       "      <td>2023-03-13 06:16:31</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trigyn</td>\n",
       "      <td>['aws', 'flow']</td>\n",
       "      <td>{'cloud': ['aws'], 'other': ['flow']}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>785741 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             job_title_short  \\\n",
       "0       Senior Data Engineer   \n",
       "1               Data Analyst   \n",
       "2              Data Engineer   \n",
       "3              Data Engineer   \n",
       "4              Data Engineer   \n",
       "...                      ...   \n",
       "785736     Software Engineer   \n",
       "785737          Data Analyst   \n",
       "785738      Business Analyst   \n",
       "785739         Data Engineer   \n",
       "785740     Software Engineer   \n",
       "\n",
       "                                                job_title  \\\n",
       "0       Senior Clinical Data Engineer / Principal Clin...   \n",
       "1                                            Data Analyst   \n",
       "2       Data Engineer/Scientist/Analyst, Mid or Senior...   \n",
       "3       LEAD ENGINEER - PRINCIPAL ANALYST - PRINCIPAL ...   \n",
       "4                                  Data Engineer- Sr Jobs   \n",
       "...                                                   ...   \n",
       "785736                                    DevOps Engineer   \n",
       "785737                                   CRM Data Analyst   \n",
       "785738                     Commercial Analyst - Start Now   \n",
       "785739  Principal Associate, Data Engineer (Remote-Eli...   \n",
       "785740                                 AWS System Analyst   \n",
       "\n",
       "                               job_location                    job_via  \\\n",
       "0                             Watertown, CT            via Work Nearby   \n",
       "1              Guadalajara, Jalisco, Mexico           via BeBee MÃ©xico   \n",
       "2                           Berlin, Germany               via LinkedIn   \n",
       "3                           San Antonio, TX          via Diversity.com   \n",
       "4                            Washington, DC         via Clearance Jobs   \n",
       "...                                     ...                        ...   \n",
       "785736                            Singapura        melalui Trabajo.org   \n",
       "785737                   Bad Rodach, Jerman  melalui BeBee Deutschland   \n",
       "785738                             Malaysia           melalui Ricebowl   \n",
       "785739  Newark, New Jersey, Amerika Serikat        melalui Recruit.net   \n",
       "785740                                India             melalui Trigyn   \n",
       "\n",
       "       job_schedule_type  job_work_from_home       search_location  \\\n",
       "0              Full-time               False  Texas, United States   \n",
       "1              Full-time               False                Mexico   \n",
       "2              Full-time               False               Germany   \n",
       "3              Full-time               False  Texas, United States   \n",
       "4              Full-time               False                 Sudan   \n",
       "...                  ...                 ...                   ...   \n",
       "785736   Pekerjaan tetap               False             Singapore   \n",
       "785737   Pekerjaan tetap               False               Germany   \n",
       "785738   Pekerjaan tetap               False              Malaysia   \n",
       "785739   Pekerjaan tetap               False                 Sudan   \n",
       "785740   Pekerjaan tetap               False                 India   \n",
       "\n",
       "           job_posted_date  job_no_degree_mention  job_health_insurance  \\\n",
       "0      2023-06-16 13:44:15                  False                 False   \n",
       "1      2023-01-14 13:18:07                  False                 False   \n",
       "2      2023-10-10 13:14:55                  False                 False   \n",
       "3      2023-07-04 13:01:41                   True                 False   \n",
       "4      2023-08-07 14:29:36                  False                 False   \n",
       "...                    ...                    ...                   ...   \n",
       "785736 2023-03-13 06:16:16                  False                 False   \n",
       "785737 2023-03-12 06:18:18                  False                 False   \n",
       "785738 2023-03-12 06:32:36                  False                 False   \n",
       "785739 2023-03-12 06:32:15                  False                 False   \n",
       "785740 2023-03-13 06:16:31                  False                 False   \n",
       "\n",
       "          job_country salary_rate  salary_year_avg  salary_hour_avg  \\\n",
       "0       United States        None              NaN              NaN   \n",
       "1              Mexico        None              NaN              NaN   \n",
       "2             Germany        None              NaN              NaN   \n",
       "3       United States        None              NaN              NaN   \n",
       "4               Sudan        None              NaN              NaN   \n",
       "...               ...         ...              ...              ...   \n",
       "785736      Singapore        None              NaN              NaN   \n",
       "785737        Germany        None              NaN              NaN   \n",
       "785738       Malaysia        None              NaN              NaN   \n",
       "785739          Sudan        None              NaN              NaN   \n",
       "785740          India        None              NaN              NaN   \n",
       "\n",
       "                              company_name  \\\n",
       "0                     Boehringer Ingelheim   \n",
       "1               Hewlett Packard Enterprise   \n",
       "2                 ALPHA Augmented Services   \n",
       "3             Southwest Research Institute   \n",
       "4                          Kristina Daniel   \n",
       "...                                    ...   \n",
       "785736  CAREERSTAR INTERNATIONAL PTE. LTD.   \n",
       "785737                    HABA FAMILYGROUP   \n",
       "785738               Lendlease Corporation   \n",
       "785739                         Capital One   \n",
       "785740                              Trigyn   \n",
       "\n",
       "                                               job_skills  \\\n",
       "0                                                    None   \n",
       "1       ['r', 'python', 'sql', 'nosql', 'power bi', 't...   \n",
       "2       ['python', 'sql', 'c#', 'azure', 'airflow', 'd...   \n",
       "3       ['python', 'c++', 'java', 'matlab', 'aws', 'te...   \n",
       "4       ['bash', 'python', 'oracle', 'aws', 'ansible',...   \n",
       "...                                                   ...   \n",
       "785736  ['bash', 'python', 'perl', 'linux', 'unix', 'k...   \n",
       "785737                     ['sas', 'sas', 'sql', 'excel']   \n",
       "785738                            ['powerpoint', 'excel']   \n",
       "785739  ['python', 'go', 'nosql', 'sql', 'mongo', 'she...   \n",
       "785740                                    ['aws', 'flow']   \n",
       "\n",
       "                                          job_type_skills  \n",
       "0                                                    None  \n",
       "1       {'analyst_tools': ['power bi', 'tableau'], 'pr...  \n",
       "2       {'analyst_tools': ['dax'], 'cloud': ['azure'],...  \n",
       "3       {'cloud': ['aws'], 'libraries': ['tensorflow',...  \n",
       "4       {'cloud': ['oracle', 'aws'], 'other': ['ansibl...  \n",
       "...                                                   ...  \n",
       "785736  {'os': ['linux', 'unix'], 'other': ['kubernete...  \n",
       "785737  {'analyst_tools': ['sas', 'excel'], 'programmi...  \n",
       "785738         {'analyst_tools': ['powerpoint', 'excel']}  \n",
       "785739  {'cloud': ['aws', 'snowflake', 'azure', 'redsh...  \n",
       "785740              {'cloud': ['aws'], 'other': ['flow']}  \n",
       "\n",
       "[785741 rows x 17 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .fillna()\n",
    "### AnlamÄ±:\n",
    "* Eksik (NaN, boÅŸ) deÄŸerleri doldurmak iÃ§in kullanÄ±lÄ±r.\n",
    "### Ne iÅŸe yarar?\n",
    "* Veri setinde eksik deÄŸerler varsa, bunlarÄ± bir deÄŸerle (0, ortalama, \"bilinmiyor\" gibi) otomatik doldurur.\n",
    "### Neden Ã¶nemli?\n",
    "* Eksik veriler, analizleri ve modellemeleri bozar. Ã–nce doldurmazsak iÅŸlemler hata verebilir.\n",
    "\n",
    "\n",
    "1. pandas.DataFrame.fillna\n",
    "DataFrame.fillna(value=None, *, method=None, axis=None, inplace=False, limit=None, downcast=<no_default>)[source]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .drop_duplicates()\n",
    "### AnlamÄ±:\n",
    "* Veri setindeki tekrar eden (aynÄ±) satÄ±rlarÄ± silmek iÃ§in kullanÄ±lÄ±r.\n",
    "### Ne iÅŸe yarar?\n",
    "* EÄŸer aynÄ± veri birden fazla kez varsa, sadece bir tanesini tutar, diÄŸer kopyalarÄ± kaldÄ±rÄ±r.\n",
    "### Neden Ã¶nemli?\n",
    "* AynÄ± verilerin birden fazla olmasÄ± analiz sonuÃ§larÄ±nÄ± yanlÄ±ÅŸ yapar. Bu yÃ¼zden tekrarlarÄ± temizleriz.\n",
    "\n",
    "1. DataFrame.drop_duplicates(subset=None, *, keep='first', inplace=False, ignore_index=False)[source]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
